[project]
name = "talky-talky"
version = "0.2.0"
description = "Text-to-Speech MCP server with pluggable engine support for AI agents"
readme = "README.md"
license = "MIT"
requires-python = ">=3.11"
dependencies = [
    "mcp>=1.0.0",
    "requests>=2.28.0",
    # Audio processing
    "pydub>=0.25.0",
    "soundfile>=0.12.0",
    "numpy>=1.26.0",  # Ensure compatible numpy for Python 3.12+
]

[project.optional-dependencies]
# Whisper transcription (via transformers - best accuracy)
whisper = [
    "torch>=2.0.0",
    "transformers>=4.35.0",
]
# Faster-Whisper transcription (CTranslate2 optimized - 4x faster)
faster-whisper = [
    "faster-whisper>=1.0.0",
]
# All transcription engines
transcription = [
    "talky-talky[whisper,faster-whisper]",
]
# Maya1 TTS support (voice design from descriptions)
maya1 = [
    "torch>=2.0.0",
    "transformers>=4.35.0",
    "snac",
]
# Chatterbox TTS support (voice cloning with emotion control)
# Also includes Chatterbox Turbo (fast voice cloning)
chatterbox = [
    "chatterbox-tts>=0.1.0",
    "numpy<2.4",  # Chatterbox requires numpy < 2.4 for numba compatibility
    "onnx==1.16.0",  # Pin onnx for ml_dtypes compatibility
]
# MiraTTS support (fast voice cloning with 48kHz output)
# Uses transformers backend for cross-platform compatibility (CUDA, MPS, CPU)
mira = [
    "torch>=2.0.0",
    "transformers>=4.35.0",
    "ncodec @ git+https://github.com/ysharma3501/FastBiCodec.git",
    "fastaudiosr @ git+https://github.com/ysharma3501/FlashSR.git",
    "librosa>=0.10.0",
    "einops>=0.6.0",
    "onnxruntime>=1.15.0",
]
# XTTS-v2 support (multilingual voice cloning)
# Works on CUDA, MPS, and CPU
xtts = [
    "TTS>=0.22.0",
]
# Kokoro support (voice selection from 54 pre-built voices)
# Requires espeak-ng system dependency
kokoro = [
    "kokoro>=0.9.2",
]
# Soprano support (ultra-fast CUDA TTS)
# CUDA GPU required - no CPU/MPS support
soprano = [
    "soprano-tts",
]
# VibeVoice support (Microsoft real-time and long-form TTS)
# Note: VibeVoice requires cloning and installing from source:
# git clone https://github.com/microsoft/VibeVoice.git && pip install -e .
# Not included in tts extra - requires separate environment due to dependency conflicts
vibevoice = [
    # Base dependencies only - full VibeVoice requires source install
    "soundfile>=0.12.0",
]
# CosyVoice3 support (Alibaba multilingual voice cloning)
# Requires cloning: git clone --recursive https://github.com/FunAudioLLM/CosyVoice.git
# and: pip install -r requirements.txt
# Note: CosyVoice has complex dependencies that require manual setup
cosyvoice = [
    "huggingface_hub>=0.20.0",
    "torchaudio>=2.0.0",
    # Note: Full CosyVoice requires cloning the repo and installing requirements.txt
]
# SeamlessM4T v2 support (multilingual TTS with translation)
# Meta's 2.3B parameter model with 35 languages for speech output
# License: CC-BY-NC-4.0 (non-commercial use only)
seamlessm4t = [
    "torch>=2.0.0",
    "transformers>=4.35.0",
    "sentencepiece>=0.1.99",
]
# SongGeneration/LeVo support (AI song generation from lyrics)
# Tencent's text-to-song model - generates vocals + accompaniment
# CUDA GPU required (10-28GB VRAM depending on model)
# Note: Full setup requires cloning the LeVo repo for third_party dependencies
# See: https://github.com/tencent-ailab/songgeneration
songgen-levo = [
    "torch>=2.6.0",
    "torchaudio>=2.6.0",
    "transformers>=4.37.0",
    "huggingface_hub>=0.25.0",
    "pyyaml>=6.0",
    "einops>=0.8.0",
    "librosa>=0.10.0",
    "soundfile>=0.12.0",
]
# ACE-Step support (AI song generation foundation model)
# Supports Apple Silicon (MPS) and CUDA
# MPS requires 36GB+ unified memory, CUDA requires 12GB+ VRAM
# IMPORTANT: ACE-Step conflicts with chatterbox due to diffusers version mismatch
# (ACE-Step needs diffusers>=0.33.0, chatterbox needs diffusers==0.29.0)
# Must be installed in a SEPARATE environment without chatterbox.
# See: https://github.com/ace-step/ACE-Step
# Install: pip install git+https://github.com/ace-step/ACE-Step.git
acestep = [
    # Base dependencies only - ACE-Step requires separate install due to conflicts
    "huggingface_hub>=0.20.0",
    "torchaudio>=2.0.0",
]
# Song generation extras (choose one based on your needs)
# NOTE: songgen-levo and acestep have dependency conflicts, install separately
songgen = [
    "talky-talky[songgen-levo]",
]
# All TTS engines (core engines without dependency conflicts)
tts = [
    "talky-talky[maya1,chatterbox,mira,xtts,kokoro,soprano,seamlessm4t]",
]

# =============================================================================
# Platform-specific extras - choose based on your hardware
# =============================================================================

# macOS (Apple Silicon or Intel) - excludes CUDA-only engines (mira, soprano)
macos = [
    "talky-talky[maya1,chatterbox,xtts,kokoro,seamlessm4t]",
]
# macOS with song generation base dependencies
# NOTE: To use ACE-Step, install separately: pip install git+https://github.com/ace-step/ACE-Step.git
# ACE-Step conflicts with chatterbox (diffusers versions), use macos-songgen instead of macos when needed
macos-songgen = [
    "talky-talky[maya1,xtts,kokoro,seamlessm4t,acestep]",
]
# macOS with transcription support
macos-transcription = [
    "talky-talky[macos,transcription]",
]
# macOS with analysis support (TTS self-verification)
macos-analysis = [
    "talky-talky[macos,analysis]",
]
# macOS full - all compatible TTS, transcription, analysis, and voice modulation
macos-full = [
    "talky-talky[macos,transcription,analysis,voice-modulation]",
]
# macOS complete - same as macos-full
# Note: For ACE-Step song generation, use macos-songgen (excludes chatterbox)
# then install ACE-Step: pip install git+https://github.com/ace-step/ACE-Step.git
macos-complete = [
    "talky-talky[macos-full]",
]

# Linux/Windows with NVIDIA CUDA GPU - includes all engines
linux-cuda = [
    "talky-talky[maya1,chatterbox,mira,xtts,kokoro,soprano,seamlessm4t]",
]
# Linux CUDA with song generation (CUDA required)
linux-cuda-songgen = [
    "talky-talky[linux-cuda,songgen]",
]
# Linux CUDA with transcription support
linux-cuda-transcription = [
    "talky-talky[linux-cuda,transcription]",
]
# Linux CUDA with analysis support (TTS self-verification)
linux-cuda-analysis = [
    "talky-talky[linux-cuda,analysis]",
]
# Linux CUDA full - all TTS engines, transcription, analysis, and voice modulation
linux-cuda-full = [
    "talky-talky[linux-cuda,transcription,analysis,voice-modulation]",
]
# Linux CUDA complete - everything including song generation
linux-cuda-complete = [
    "talky-talky[linux-cuda-full,songgen]",
]

# CPU-only (no GPU) - same as macOS, excludes CUDA-only engines
cpu = [
    "talky-talky[maya1,chatterbox,xtts,kokoro,seamlessm4t]",
]
# CPU with transcription
cpu-transcription = [
    "talky-talky[cpu,transcription]",
]
# CPU with analysis
cpu-analysis = [
    "talky-talky[cpu,analysis]",
]
# CPU full - all compatible TTS, transcription, analysis, and voice modulation
cpu-full = [
    "talky-talky[cpu,transcription,analysis,voice-modulation]",
]
# Emotion detection (emotion2vec via FunASR)
emotion2vec = [
    "funasr>=1.0.0",
    "modelscope>=1.9.0",
    "torch>=2.0.0",
]
# Voice similarity (Resemblyzer)
resemblyzer = [
    "resemblyzer>=0.1.3",
]
# Speech quality assessment (NISQA via TorchMetrics)
nisqa = [
    "torchmetrics>=1.0.0",
    "librosa>=0.10.0",
    "requests>=2.28.0",
    "torch>=2.0.0",
]
# All analysis engines for TTS self-verification
analysis = [
    "talky-talky[emotion2vec,resemblyzer,nisqa]",
]
# Voice modulation (pitch shifting, time stretching, formant shifting)
# Note: librosa (already in nisqa) provides pitch/time tools
# pyworld is optional for high-quality formant shifting
voice-modulation = [
    "librosa>=0.10.0",  # Pitch shifting, time stretching
    "pyworld>=0.3.0",   # High-quality formant shifting (WORLD vocoder)
]
# Voice modulation without pyworld (uses librosa approximation for formants)
voice-modulation-lite = [
    "librosa>=0.10.0",
]
dev = [
    "pytest>=7.0.0",
    "pytest-asyncio>=0.21.0",
    "ruff>=0.1.0",
    "pre-commit>=3.0.0",
]

[project.scripts]
talky-talky = "talky_talky.server.app:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.metadata]
allow-direct-references = true

[tool.hatch.build.targets.wheel]
packages = ["talky_talky"]

[tool.uv]
# pkuseg (chatterbox dependency) needs numpy during build but doesn't declare it
extra-build-dependencies = { pkuseg = ["numpy"] }

[tool.ruff]
line-length = 100
target-version = "py310"
